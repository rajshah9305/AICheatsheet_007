<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Cheatsheet 007 - Complete Guide</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }

        .header h1 {
            color: white;
            font-size: 3rem;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            color: rgba(255, 255, 255, 0.8);
            font-size: 1.2rem;
        }

        .search-container {
            position: relative;
            margin: 30px 0;
        }

        .search-box {
            width: 100%;
            padding: 15px 50px 15px 20px;
            border: none;
            border-radius: 50px;
            font-size: 16px;
            background: rgba(255, 255, 255, 0.9);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            outline: none;
            transition: all 0.3s ease;
        }

        .search-box:focus {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.15);
        }

        .search-icon {
            position: absolute;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #666;
            font-size: 18px;
        }

        .nav-tabs {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-bottom: 30px;
            justify-content: center;
        }

        .tab-button {
            padding: 12px 24px;
            border: none;
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 500;
            backdrop-filter: blur(10px);
        }

        .tab-button:hover, .tab-button.active {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }

        .content-sections {
            display: grid;
            gap: 25px;
        }

        .section {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            backdrop-filter: blur(10px);
            transition: all 0.3s ease;
            display: none;
        }

        .section.active {
            display: block;
            animation: fadeIn 0.5s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .section h2 {
            color: #333;
            margin-bottom: 20px;
            font-size: 1.8rem;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }

        .section h3 {
            color: #555;
            margin: 20px 0 10px 0;
            font-size: 1.3rem;
        }

        .code-block {
            background: #2d3748;
            color: #e2e8f0;
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            position: relative;
        }

        .code-block::before {
            content: 'Code';
            position: absolute;
            top: 5px;
            right: 10px;
            background: #667eea;
            color: white;
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.8rem;
        }

        .highlight {
            background: #ffeaa7;
            padding: 2px 4px;
            border-radius: 3px;
            font-weight: bold;
        }

        .card-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .card {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 20px;
            border-radius: 15px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }

        .card:hover {
            transform: translateY(-5px);
        }

        .card h4 {
            margin-bottom: 10px;
            font-size: 1.2rem;
        }

        .formula {
            background: #f8f9fa;
            border-left: 4px solid #007bff;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            font-family: 'Times New Roman', serif;
            font-style: italic;
        }

        .tip {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }

        .tip::before {
            content: 'üí° ';
            font-weight: bold;
        }

        .warning {
            background: #f8d7da;
            border: 1px solid #f5c6cb;
            color: #721c24;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }

        .warning::before {
            content: '‚ö†Ô∏è ';
            font-weight: bold;
        }

        .toggle-button {
            background: #667eea;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 20px;
            cursor: pointer;
            margin: 10px 0;
            transition: all 0.3s ease;
        }

        .toggle-button:hover {
            background: #5a6fd8;
            transform: scale(1.05);
        }

        .collapsible-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
        }

        .collapsible-content.expanded {
            max-height: 1000px;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 2rem;
            }
            
            .nav-tabs {
                flex-direction: column;
            }
            
            .tab-button {
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header class="header">
            <h1><i class="fas fa-robot"></i> AI Cheatsheet 007</h1>
            <p>Your Complete Guide to Artificial Intelligence Concepts & Implementation</p>
        </header>

        <div class="search-container">
            <input type="text" class="search-box" id="searchBox" placeholder="Search for AI concepts, algorithms, or implementations...">
            <i class="fas fa-search search-icon"></i>
        </div>

        <nav class="nav-tabs">
            <button class="tab-button active" data-section="machine-learning">Machine Learning</button>
            <button class="tab-button" data-section="deep-learning">Deep Learning</button>
            <button class="tab-button" data-section="nlp">NLP</button>
            <button class="tab-button" data-section="computer-vision">Computer Vision</button>
            <button class="tab-button" data-section="algorithms">Algorithms</button>
            <button class="tab-button" data-section="tools">Tools & Libraries</button>
        </nav>

        <div class="content-sections">
            <!-- Machine Learning Section -->
            <section class="section active" id="machine-learning">
                <h2><i class="fas fa-brain"></i> Machine Learning Fundamentals</h2>
                
                <h3>Core Concepts</h3>
                <div class="card-grid">
                    <div class="card">
                        <h4>Supervised Learning</h4>
                        <p>Learning with labeled data to predict outcomes for new inputs.</p>
                        <div class="formula">
                            y = f(x) + Œµ
                        </div>
                    </div>
                    <div class="card">
                        <h4>Unsupervised Learning</h4>
                        <p>Finding hidden patterns in data without labels.</p>
                        <div class="formula">
                            Find structure in X without y
                        </div>
                    </div>
                    <div class="card">
                        <h4>Reinforcement Learning</h4>
                        <p>Learning through trial and error with rewards and penalties.</p>
                        <div class="formula">
                            Q(s,a) = R + Œ≥ max Q(s',a')
                        </div>
                    </div>
                </div>

                <h3>Linear Regression Implementation</h3>
                <div class="code-block">
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Sample data
X = np.random.randn(100, 1)
y = 2 * X.flatten() + 1 + np.random.randn(100) * 0.1

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.4f}")
print(f"R¬≤: {r2:.4f}")
                </div>

                <div class="tip">
                    Always split your data into training and testing sets to avoid overfitting!
                </div>

                <h3>Classification Algorithms</h3>
                <button class="toggle-button" onclick="toggleContent('classification-content')">Show Classification Examples</button>
                <div class="collapsible-content" id="classification-content">
                    <div class="code-block">
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)

# Support Vector Machine
svm = SVC(kernel='rbf', random_state=42)
svm.fit(X_train, y_train)
svm_pred = svm.predict(X_test)

# K-Nearest Neighbors
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)

# Evaluation
print("Random Forest Results:")
print(classification_report(y_test, rf_pred))
                    </div>
                </div>
            </section>

            <!-- Deep Learning Section -->
            <section class="section" id="deep-learning">
                <h2><i class="fas fa-network-wired"></i> Deep Learning</h2>
                
                <h3>Neural Network Basics</h3>
                <div class="formula">
                    <strong>Forward Propagation:</strong><br>
                    z = W¬∑x + b<br>
                    a = œÉ(z) where œÉ is activation function
                </div>

                <div class="code-block">
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam

# Build a simple neural network
model = Sequential([
    Dense(128, activation='relu', input_shape=(784,)),
    BatchNormalization(),
    Dropout(0.3),
    Dense(64, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(10, activation='softmax')
])

# Compile model
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Model summary
model.summary()

# Train model
history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=50,
    validation_split=0.2,
    verbose=1
)
                </div>

                <h3>Convolutional Neural Networks (CNN)</h3>
                <div class="code-block">
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten

# CNN for image classification
cnn_model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

cnn_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
                </div>

                <div class="warning">
                    CNNs require proper data preprocessing and normalization for optimal performance!
                </div>
            </section>

            <!-- NLP Section -->
            <section class="section" id="nlp">
                <h2><i class="fas fa-comments"></i> Natural Language Processing</h2>
                
                <h3>Text Preprocessing</h3>
                <div class="code-block">
import nltk
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer

# Download required NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    
    # Remove special characters and digits
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    
    # Tokenize
    tokens = word_tokenize(text)
    
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words]
    
    # Lemmatization
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(token) for token in tokens]
    
    return ' '.join(tokens)

# Example usage
sample_text = "This is a sample text for preprocessing! It contains various symbols & numbers 123."
cleaned_text = preprocess_text(sample_text)
print(f"Original: {sample_text}")
print(f"Cleaned: {cleaned_text}")
                </div>

                <h3>Sentiment Analysis</h3>
                <div class="code-block">
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

def analyze_sentiment(text):
    # Using TextBlob
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    
    # Using VADER
    analyzer = SentimentIntensityAnalyzer()
    vader_scores = analyzer.polarity_scores(text)
    
    return {
        'textblob_polarity': polarity,
        'vader_positive': vader_scores['pos'],
        'vader_neutral': vader_scores['neu'],
        'vader_negative': vader_scores['neg'],
        'vader_compound': vader_scores['compound']
    }

# Example
text = "I love this amazing product! It's fantastic!"
sentiment = analyze_sentiment(text)
print(sentiment)
                </div>

                <h3>Word Embeddings with Word2Vec</h3>
                <div class="code-block">
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess

# Sample sentences
sentences = [
    "the quick brown fox jumps over the lazy dog",
    "machine learning is a subset of artificial intelligence",
    "deep learning uses neural networks with multiple layers",
    "natural language processing deals with human language"
]

# Preprocess sentences
processed_sentences = [simple_preprocess(sentence) for sentence in sentences]

# Train Word2Vec model
model = Word2Vec(
    sentences=processed_sentences,
    vector_size=100,
    window=5,
    min_count=1,
    workers=4,
    sg=0  # CBOW algorithm
)

# Find similar words
try:
    similar_words = model.wv.most_similar('learning', topn=3)
    print("Words similar to 'learning':", similar_words)
except KeyError:
    print("Word not found in vocabulary")

# Get word vector
word_vector = model.wv['machine']
print(f"Vector for 'machine': {word_vector[:5]}...")  # Show first 5 dimensions
                </div>
            </section>

            <!-- Computer Vision Section -->
            <section class="section" id="computer-vision">
                <h2><i class="fas fa-eye"></i> Computer Vision</h2>
                
                <h3>Image Processing Basics</h3>
                <div class="code-block">
import cv2
import numpy as np
from matplotlib import pyplot as plt

def process_image(image_path):
    # Read image
    img = cv2.imread(image_path)
    
    # Convert BGR to RGB (for matplotlib)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # Apply Gaussian blur
    blurred = cv2.GaussianBlur(gray, (15, 15), 0)
    
    # Edge detection using Canny
    edges = cv2.Canny(blurred, 50, 150)
    
    # Find contours
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Draw contours on original image
    img_contours = img_rgb.copy()
    cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 2)
    
    return img_rgb, gray, edges, img_contours

# Note: Replace 'path_to_image.jpg' with actual image path
# img_rgb, gray, edges, contours_img = process_image('path_to_image.jpg')
                </div>

                <h3>Object Detection with YOLO</h3>
                <div class="code-block">
import cv2
import numpy as np

def detect_objects_yolo(image_path, weights_path, config_path, names_path):
    # Load YOLO
    net = cv2.dnn.readNet(weights_path, config_path)
    
    # Load class names
    with open(names_path, 'r') as f:
        classes = [line.strip() for line in f.readlines()]
    
    # Load image
    image = cv2.imread(image_path)
    height, width, channels = image.shape
    
    # Prepare image for YOLO
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    net.setInput(blob)
    
    # Run inference
    layer_names = net.getLayerNames()
    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]
    outs = net.forward(output_layers)
    
    # Process detections
    class_ids = []
    confidences = []
    boxes = []
    
    for out in outs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            
            if confidence > 0.5:  # Confidence threshold
                # Object detected
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)
                
                # Rectangle coordinates
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)
                
                boxes.append([x, y, w, h])
                confidences.append(float(confidence))
                class_ids.append(class_id)
    
    # Apply Non-Maximum Suppression
    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)
    
    # Draw bounding boxes
    for i in range(len(boxes)):
        if i in indexes:
            x, y, w, h = boxes[i]
            label = str(classes[class_ids[i]])
            confidence = confidences[i]
            
            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(image, f"{label} {confidence:.2f}", (x, y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    return image

# Usage example (requires YOLO weights, config, and names files)
# detected_image = detect_objects_yolo('image.jpg', 'yolo.weights', 'yolo.cfg', 'coco.names')
                </div>

                <div class="tip">
                    For real-time object detection, consider using lighter models like MobileNet or EfficientDet!
                </div>
            </section>

            <!-- Algorithms Section -->
            <section class="section" id="algorithms">
                <h2><i class="fas fa-cogs"></i> Key Algorithms</h2>
                
                <h3>Gradient Descent</h3>
                <div class="formula">
                    Œ∏ = Œ∏ - Œ± ‚àáJ(Œ∏)<br>
                    where Œ± is learning rate and ‚àáJ(Œ∏) is the gradient
                </div>
                
                <div class="code-block">
import numpy as np
import matplotlib.pyplot as plt

def gradient_descent(X, y, learning_rate=0.01, epochs=1000):
    # Initialize parameters
    m, n = X.shape
    theta = np.zeros(n)
    cost_history = []
    
    for epoch in range(epochs):
        # Forward propagation
        h = X.dot(theta)
        
        # Calculate cost
        cost = (1 / (2 * m)) * np.sum((h - y) ** 2)
        cost_history.append(cost)
        
        # Calculate gradients
        gradients = (1 / m) * X.T.dot(h - y)
        
        # Update parameters
        theta = theta - learning_rate * gradients
        
        # Print cost every 100 epochs
        if epoch % 100 == 0:
            print(f"Epoch {epoch}, Cost: {cost:.4f}")
    
    return theta, cost_history

# Example usage
# Assuming X and y are your features and target
# theta_final, costs = gradient_descent(X, y)
                </div>

                <h3>K-Means Clustering</h3>
                <div class="code-block">
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

def kmeans_clustering(X, k=3, max_iters=100):
    # Initialize centroids randomly
    centroids = X[np.random.choice(X.shape[0], k, replace=False)]
    
    for _ in range(max_iters):
        # Assign points to closest centroid
        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))
        labels = np.argmin(distances, axis=0)
        
        # Update centroids
        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])
        
        # Check for convergence
        if np.all(centroids == new_centroids):
            break
        
        centroids = new_centroids
    
    return labels, centroids

# Using scikit-learn for comparison
def sklearn_kmeans(X, k=3):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X)
    centroids = kmeans.cluster_centers_
    
    return labels, centroids

# Example with synthetic data
np.random.seed(42)
X = np.random.randn(100, 2)

# Custom implementation
labels_custom, centroids_custom = kmeans_clustering(X, k=3)

# Scikit-learn implementation
labels_sklearn, centroids_sklearn = sklearn_kmeans(X, k=3)

print("Custom K-means centroids:")
print(centroids_custom)
print("\nScikit-learn centroids:")
print(centroids_sklearn)
                </div>

                <h3>Decision Trees</h3>
                <div class="code-block">
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.datasets import make_classification
import numpy as np

# Create sample data
X, y = make_classification(n_samples=100, n_features=4, n_informative=3, 
                          n_redundant=1, random_state=42)

# Create and train decision tree
dt = DecisionTreeClassifier(
    criterion='gini',  # or 'entropy'
    max_depth=5,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42
)

dt.fit(X, y)

# Print tree structure
tree_rules = export_text(dt, feature_names=[f'feature_{i}' for i in range(X.shape[1])])
print("Decision Tree Rules:")
print(tree_rules[:500] + "...")  # Print first 500 characters

# Calculate feature importance
feature_importance = dt.feature_importances_
print("\nFeature Importance:")
for i, importance in enumerate(feature_importance):
    print(f"Feature {i}: {importance:.4f}")
                </div>
            </section>

            <!-- Tools & Libraries Section -->
            <section class="section" id="tools">
                <h2><i class="fas fa-tools"></i> Essential Tools & Libraries</h2>
                
                <h3>Python Libraries for AI/ML</h3>
                <div class="card-grid">
                    <div class="card">
                        <h4>üìä Data Science</h4>
                        <ul>
                            <li><strong>NumPy</strong> - Numerical computing</li>
                            <li><strong>Pandas</strong> - Data manipulation</li>
                            <li><strong>Matplotlib/Seaborn</strong> - Visualization</li>
                        </ul>
                    </div>
                    <div class="card">
                        <h4>ü§ñ Machine Learning</h4>
                        <ul>
                            <li><strong>Scikit-learn</strong> - ML algorithms</li>
                            <li><strong>XGBoost</strong> - Gradient boosting</li>
                            <li><strong>LightGBM</strong> - Fast gradient boosting</li>
                        </ul>
                    </div>
                    <div class="card">
                        <h4>üß† Deep Learning</h4>
                        <ul>
                            <li><strong>TensorFlow</strong> - Google's ML platform</li>
                            <li><strong>PyTorch</strong> - Facebook's ML library</li>
                            <li><strong>Keras</strong> - High-level neural networks</li>
                        </ul>
                    </div>
                    <div class="card">
                        <h4>üí¨ NLP</h4>
                        <ul>
                            <li><strong>NLTK</strong> - Natural language toolkit</li>
                            <li><strong>spaCy</strong> - Industrial NLP</li>
                            <li><strong>Transformers</strong> - Hugging Face models</li>
                        </ul>
                    </div>
                    <div class="card">
                        <h4>üëÅÔ∏è Computer Vision</h4>
                        <ul>
                            <li><strong>OpenCV</strong> - Computer vision library</li>
                            <li><strong>Pillow</strong> - Image processing</li>
                            <li><strong>ImageIO</strong> - Image I/O operations</li>
                        </ul>
                    </div>
                    <div class="card">
                        <h4>‚òÅÔ∏è Cloud & Deployment</h4>
                        <ul>
                            <li><strong>AWS SageMaker</strong> - Amazon ML platform</li>
                            <li><strong>Google Colab</strong> - Free GPU notebooks</li>
                            <li><strong>Docker</strong> - Containerization</li>
                        </ul>
                    </div>
                </div>

                <h3>Model Deployment with Flask</h3>
                <div class="code-block">
from flask import Flask, request, jsonify
import joblib
import numpy as np
import pandas as pd

# Initialize Flask app
app = Flask(__name__)

# Load pre-trained model
model = joblib.load('trained_model.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    try:
        # Get data from request
        data = request.get_json()
        
        # Convert to DataFrame
        features = pd.DataFrame([data])
        
        # Make prediction
        prediction = model.predict(features)
        probability = model.predict_proba(features)
        
        # Return results
        return jsonify({
            'prediction': int(prediction[0]),
            'probability': probability[0].tolist(),
            'status': 'success'
        })
    
    except Exception as e:
        return jsonify({
            'error': str(e),
            'status': 'error'
        }), 400

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({'status': 'healthy'})

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
                </div>

                <h3>Docker Configuration</h3>
                <div class="code-block">
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 5000

# Run the application
CMD ["python", "app.py"]

# requirements.txt content:
# flask==2.3.3
# scikit-learn==1.3.0
# pandas==2.0.3
# numpy==1.24.3
# joblib==1.3.2
                </div>

                <h3>Model Monitoring & MLOps</h3>
                <div class="code-block">
import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient
import logging

# Set up MLflow tracking
mlflow.set_tracking_uri("http://localhost:5000")
mlflow.set_experiment("ai_cheatsheet_experiment")

def train_and_log_model(X_train, X_test, y_train, y_test, model, model_name):
    """Train model and log metrics, parameters, and artifacts to MLflow"""
    
    with mlflow.start_run():
        # Train model
        model.fit(X_train, y_train)
        
        # Make predictions
        train_predictions = model.predict(X_train)
        test_predictions = model.predict(X_test)
        
        # Calculate metrics
        train_accuracy = accuracy_score(y_train, train_predictions)
        test_accuracy = accuracy_score(y_test, test_predictions)
        
        # Log parameters
        if hasattr(model, 'get_params'):
            mlflow.log_params(model.get_params())
        
        # Log metrics
        mlflow.log_metric("train_accuracy", train_accuracy)
        mlflow.log_metric("test_accuracy", test_accuracy)
        mlflow.log_metric("overfitting", train_accuracy - test_accuracy)
        
        # Log model
        mlflow.sklearn.log_model(model, model_name)
        
        # Log additional artifacts
        with open("model_summary.txt", "w") as f:
            f.write(f"Model: {model_name}\n")
            f.write(f"Train Accuracy: {train_accuracy:.4f}\n")
            f.write(f"Test Accuracy: {test_accuracy:.4f}\n")
        
        mlflow.log_artifact("model_summary.txt")
        
        logging.info(f"Model {model_name} logged successfully")
        
        return model

# Example usage
# trained_model = train_and_log_model(X_train, X_test, y_train, y_test, 
#                                   RandomForestClassifier(), "random_forest")
                </div>

                <div class="tip">
                    Use MLflow or similar tools to track experiments, compare models, and manage the ML lifecycle!
                </div>

                <h3>Data Pipeline with Apache Airflow</h3>
                <div class="code-block">
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.operators.bash_operator import BashOperator
from datetime import datetime, timedelta
import pandas as pd
import joblib

# Default arguments
default_args = {
    'owner': 'ai_team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}

# Define DAG
dag = DAG(
    'ml_pipeline',
    default_args=default_args,
    description='Machine Learning Pipeline',
    schedule_interval='@daily',
    catchup=False
)

def extract_data(**context):
    """Extract data from source"""
    # Your data extraction logic here
    data = pd.read_csv('/path/to/source/data.csv')
    data.to_csv('/tmp/raw_data.csv', index=False)
    return '/tmp/raw_data.csv'

def transform_data(**context):
    """Transform and clean data"""
    data = pd.read_csv('/tmp/raw_data.csv')
    
    # Data cleaning and transformation
    data = data.dropna()
    data = data[data['target'] >= 0]  # Remove invalid targets
    
    # Feature engineering
    data['new_feature'] = data['feature1'] * data['feature2']
    
    data.to_csv('/tmp/processed_data.csv', index=False)
    return '/tmp/processed_data.csv'

def train_model(**context):
    """Train ML model"""
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split
    
    data = pd.read_csv('/tmp/processed_data.csv')
    X = data.drop('target', axis=1)
    y = data['target']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    
    model = RandomForestClassifier(n_estimators=100)
    model.fit(X_train, y_train)
    
    # Save model
    joblib.dump(model, '/tmp/trained_model.pkl')
    
    # Calculate and log accuracy
    accuracy = model.score(X_test, y_test)
    print(f"Model accuracy: {accuracy:.4f}")
    
    return '/tmp/trained_model.pkl'

# Define tasks
extract_task = PythonOperator(
    task_id='extract_data',
    python_callable=extract_data,
    dag=dag
)

transform_task = PythonOperator(
    task_id='transform_data',
    python_callable=transform_data,
    dag=dag
)

train_task = PythonOperator(
    task_id='train_model',
    python_callable=train_model,
    dag=dag
)

deploy_task = BashOperator(
    task_id='deploy_model',
    bash_command='cp /tmp/trained_model.pkl /production/models/',
    dag=dag
)

# Set task dependencies
extract_task >> transform_task >> train_task >> deploy_task
                </div>
            </section>
        </div>

        <!-- Footer with Quick Reference -->
        <div class="section" style="display: block; margin-top: 40px; background: rgba(255, 255, 255, 0.1); backdrop-filter: blur(10px);">
            <h2 style="color: white; text-align: center;"><i class="fas fa-bookmark"></i> Quick Reference</h2>
            
            <div class="card-grid">
                <div class="card" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);">
                    <h4>üìà Model Evaluation Metrics</h4>
                    <ul>
                        <li><strong>Accuracy:</strong> (TP + TN) / (TP + TN + FP + FN)</li>
                        <li><strong>Precision:</strong> TP / (TP + FP)</li>
                        <li><strong>Recall:</strong> TP / (TP + FN)</li>
                        <li><strong>F1-Score:</strong> 2 * (Precision * Recall) / (Precision + Recall)</li>
                    </ul>
                </div>
                
                <div class="card" style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);">
                    <h4>üéØ Common Activation Functions</h4>
                    <ul>
                        <li><strong>ReLU:</strong> f(x) = max(0, x)</li>
                        <li><strong>Sigmoid:</strong> f(x) = 1 / (1 + e^(-x))</li>
                        <li><strong>Tanh:</strong> f(x) = (e^x - e^(-x)) / (e^x + e^(-x))</li>
                        <li><strong>Softmax:</strong> f(x_i) = e^(x_i) / Œ£e^(x_j)</li>
                    </ul>
                </div>
                
                <div class="card" style="background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);">
                    <h4>üìä Loss Functions</h4>
                    <ul>
                        <li><strong>MSE:</strong> Œ£(y_true - y_pred)¬≤ / n</li>
                        <li><strong>Cross-entropy:</strong> -Œ£y_true * log(y_pred)</li>
                        <li><strong>Hinge:</strong> max(0, 1 - y_true * y_pred)</li>
                        <li><strong>Huber:</strong> Combines MSE and MAE</li>
                    </ul>
                </div>
                
                <div class="card" style="background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);">
                    <h4>‚öôÔ∏è Hyperparameter Tips</h4>
                    <ul>
                        <li><strong>Learning Rate:</strong> Start with 0.001</li>
                        <li><strong>Batch Size:</strong> 32, 64, 128 (powers of 2)</li>
                        <li><strong>Dropout:</strong> 0.2-0.5 for regularization</li>
                        <li><strong>Early Stopping:</strong> Monitor validation loss</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Tab switching functionality
        document.querySelectorAll('.tab-button').forEach(button => {
            button.addEventListener('click', () => {
                // Remove active class from all buttons and sections
                document.querySelectorAll('.tab-button').forEach(btn => btn.classList.remove('active'));
                document.querySelectorAll('.section').forEach(section => section.classList.remove('active'));
                
                // Add active class to clicked button and corresponding section
                button.classList.add('active');
                const sectionId = button.getAttribute('data-section');
                document.getElementById(sectionId).classList.add('active');
            });
        });

        // Search functionality
        document.getElementById('searchBox').addEventListener('input', function(e) {
            const searchTerm = e.target.value.toLowerCase();
            const sections = document.querySelectorAll('.section');
            
            sections.forEach(section => {
                const content = section.textContent.toLowerCase();
                const shouldShow = content.includes(searchTerm);
                
                if (searchTerm === '') {
                    // Show only active section when search is empty
                    const activeTab = document.querySelector('.tab-button.active').getAttribute('data-section');
                    section.style.display = section.id === activeTab ? 'block' : 'none';
                } else if (shouldShow) {
                    section.style.display = 'block';
                    section.classList.add('active');
                } else {
                    section.style.display = 'none';
                    section.classList.remove('active');
                }
            });
            
            // Highlight search terms
            if (searchTerm) {
                highlightSearchTerms(searchTerm);
            } else {
                removeHighlights();
            }
        });

        // Highlight search terms
        function highlightSearchTerms(term) {
            const regex = new RegExp(`(${term})`, 'gi');
            const sections = document.querySelectorAll('.section');
            
            sections.forEach(section => {
                const walker = document.createTreeWalker(
                    section,
                    NodeFilter.SHOW_TEXT,
                    null,
                    false
                );
                
                const textNodes = [];
                let node;
                while (node = walker.nextNode()) {
                    if (node.parentElement.tagName !== 'SCRIPT' && 
                        node.parentElement.tagName !== 'STYLE') {
                        textNodes.push(node);
                    }
                }
                
                textNodes.forEach(textNode => {
                    if (regex.test(textNode.textContent)) {
                        const highlightedText = textNode.textContent.replace(regex, '<mark>$1</mark>');
                        const wrapper = document.createElement('span');
                        wrapper.innerHTML = highlightedText;
                        textNode.parentElement.replaceChild(wrapper, textNode);
                    }
                });
            });
        }

        // Remove highlights
        function removeHighlights() {
            document.querySelectorAll('mark').forEach(mark => {
                mark.outerHTML = mark.innerHTML;
            });
        }

        // Toggle collapsible content
        function toggleContent(contentId) {
            const content = document.getElementById(contentId);
            const button = event.target;
            
            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                button.textContent = button.textContent.replace('Hide', 'Show');
            } else {
                content.classList.add('expanded');
                button.textContent = button.textContent.replace('Show', 'Hide');
            }
        }

        // Copy code functionality
        document.querySelectorAll('.code-block').forEach((block, index) => {
            const copyButton = document.createElement('button');
            copyButton.innerHTML = '<i class="fas fa-copy"></i>';
            copyButton.className = 'copy-button';
            copyButton.style.cssText = `
                position: absolute;
                top: 10px;
                right: 50px;
                background: #4a5568;
                color: white;
                border: none;
                padding: 5px 10px;
                border-radius: 5px;
                cursor: pointer;
                font-size: 12px;
                transition: background 0.3s ease;
            `;
            
            copyButton.addEventListener('click', () => {
                const code = block.textContent;
                navigator.clipboard.writeText(code).then(() => {
                    copyButton.innerHTML = '<i class="fas fa-check"></i>';
                    copyButton.style.background = '#38a169';
                    setTimeout(() => {
                        copyButton.innerHTML = '<i class="fas fa-copy"></i>';
                        copyButton.style.background = '#4a5568';
                    }, 2000);
                });
            });
            
            copyButton.addEventListener('mouseenter', () => {
                copyButton.style.background = '#2d3748';
            });
            
            copyButton.addEventListener('mouseleave', () => {
                copyButton.style.background = '#4a5568';
            });
            
            block.style.position = 'relative';
            block.appendChild(copyButton);
        });

        // Add smooth scrolling
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });

        // Initialize the page
        document.addEventListener('DOMContentLoaded', () => {
            // Show the first section by default
            document.getElementById('machine-learning').classList.add('active');
            
            // Add loading animation
            document.body.style.opacity = '0';
            setTimeout(() => {
                document.body.style.transition = 'opacity 0.5s ease';
                document.body.style.opacity = '1';
            }, 100);
        });

        // Add keyboard shortcuts
        document.addEventListener('keydown', (e) => {
            // Ctrl/Cmd + K to focus search
            if ((e.ctrlKey || e.metaKey) && e.key === 'k') {
                e.preventDefault();
                document.getElementById('searchBox').focus();
            }
            
            // Escape to clear search
            if (e.key === 'Escape') {
                const searchBox = document.getElementById('searchBox');
                if (searchBox === document.activeElement) {
                    searchBox.value = '';
                    searchBox.dispatchEvent(new Event('input'));
                    searchBox.blur();
                }
            }
        });
    </script>
</body>
</html>
